{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "# from keras.layers.noise import AlphaDropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network(input_shape,units1=128,units2=64,units3=8,\n",
    "                       dropout_rate1=0.2,dropout_rate2=0.1,dropout_rate3=0.1, lr=0.00004):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units1, activation='relu', input_shape=(input_shape,)))\n",
    "    # Add one hidden layer\n",
    "    model.add(Dropout(dropout_rate1))\n",
    "    model.add(Dense(units2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate2))\n",
    "    model.add(Dense(units3, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = Adam(lr=lr, epsilon=.001)  # lr=0.00004\n",
    "#     opt = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_network_2_bn(input_shape, units, dropout, epsilon, lr=0.00004):\n",
    "    units1, units2 = units\n",
    "    dropout_rate1, dropout_rate2 = dropout \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(units1, input_shape=(input_shape,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate1))\n",
    "    \n",
    "    model.add(Dense(units2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate2))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = Adam(lr=lr, epsilon=epsilon)  # lr=0.00004\n",
    "#     opt = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy', auroc])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_network_3_bn(input_shape, units, dropout, epsilon, lr=0.00004):\n",
    "    units1, units2, units3 = units\n",
    "    dropout_rate1, dropout_rate2, dropout_rate3 = dropout \n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units1, input_shape=(input_shape,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate1))\n",
    "    \n",
    "    model.add(Dense(units2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate2))\n",
    "    \n",
    "    model.add(Dense(units3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate3))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = Adam(lr=lr, epsilon=epsilon)  # lr=0.00004\n",
    "#     opt = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_network_4_bn(input_shape, units, dropout, epsilon, lr=0.00004):\n",
    "    model = Sequential()\n",
    "    \n",
    "    units1, units2, units3, units4 = units\n",
    "    dropout_rate1, dropout_rate2, dropout_rate3, dropout_rate4 = dropout\n",
    "    \n",
    "    model.add(Dense(units1, input_shape=(input_shape,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate1))\n",
    "    \n",
    "    model.add(Dense(units2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate2))\n",
    "    \n",
    "    model.add(Dense(units3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate3))\n",
    "    \n",
    "    model.add(Dense(units4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate4))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = Adam(lr=lr, epsilon=epsilon)  # lr=0.00004\n",
    "#     opt = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of SNPs:\t4119\n"
     ]
    }
   ],
   "source": [
    "data_path = '/legodata/zhaoj/cvd_risk_time2/genetic_data'\n",
    "results_path = '/legodata/zhaoj/cvd_risk_time2/src/dnn/'\n",
    "df_genetic = pd.read_csv(os.path.join(data_path, 'snps_5e6_with_demo.csv'))\n",
    "\n",
    "# cmd_arg = get_args()\n",
    "\n",
    "suffix = ''\n",
    "\n",
    "print('# of SNPs:\\t{}'.format(len(df_genetic.columns)))\n",
    "\n",
    "if True:\n",
    "    snps_col_lst = list(df_genetic.drop(['GENDER', 'AGE', 'RACE_A', 'RACE_B', 'RACE_W', 'RACE_U', 'GRID', 'CLASS'], axis=1).columns)\n",
    "    df_genetic = pd.get_dummies(df_genetic.astype('str'), columns=snps_col_lst)\n",
    "    df_genetic['CLASS'] = df_genetic['CLASS'].astype('int64')\n",
    "\n",
    "if True:\n",
    "    df_genetic = df_genetic.drop(['AGE', 'GENDER', 'RACE_A', 'RACE_U', 'RACE_W', 'RACE_B'], axis=1)\n",
    "    suffix += '_drop_demo'\n",
    "\n",
    "    \n",
    "# if cmd_arg.csv_name:\n",
    "# suffix += '_{}'.format('5e6')\n",
    "\n",
    "# df_cv, df_cv_train_history = run_network(df_cohort=df_genetic,\n",
    "#                                          results_path=results_path,\n",
    "#                                          csv_name=cmd_arg.csv_name,\n",
    "#                                          n_folds=10)\n",
    "\n",
    "# df_cv.to_csv(os.path.join(results_path, 'df_cv{}.csv'.format(suffix)), index=False)\n",
    "# df_cv_train_history.to_csv(os.path.join(results_path, 'df_cv_train_history{}.csv'.format(suffix)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37573\n",
      "37421\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRID</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>rs2843152_0</th>\n",
       "      <th>rs2843152_1</th>\n",
       "      <th>rs2843152_2</th>\n",
       "      <th>rs35465346_0</th>\n",
       "      <th>rs35465346_1</th>\n",
       "      <th>rs35465346_2</th>\n",
       "      <th>rs28470722_0</th>\n",
       "      <th>rs28470722_1</th>\n",
       "      <th>...</th>\n",
       "      <th>rs8136727_0</th>\n",
       "      <th>rs8136727_1</th>\n",
       "      <th>rs8136727_2</th>\n",
       "      <th>rs9608859_0</th>\n",
       "      <th>rs9608859_1</th>\n",
       "      <th>rs9608859_2</th>\n",
       "      <th>rs6006426_0</th>\n",
       "      <th>rs6006426_1</th>\n",
       "      <th>rs6006426_2</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R248687632</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R264130541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R240479697</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R204312273</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R294868998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         GRID  CLASS  rs2843152_0  rs2843152_1  rs2843152_2  rs35465346_0  \\\n",
       "0  R248687632      0            1            0            0             1   \n",
       "1  R264130541      0            0            1            0             0   \n",
       "2  R240479697      0            1            0            0             0   \n",
       "3  R204312273      1            0            1            0             1   \n",
       "4  R294868998      1            0            1            0             1   \n",
       "\n",
       "   rs35465346_1  rs35465346_2  rs28470722_0  rs28470722_1   ...     \\\n",
       "0             0             0             0             1   ...      \n",
       "1             1             0             0             1   ...      \n",
       "2             1             0             0             1   ...      \n",
       "3             0             0             0             0   ...      \n",
       "4             0             0             1             0   ...      \n",
       "\n",
       "   rs8136727_0  rs8136727_1  rs8136727_2  rs9608859_0  rs9608859_1  \\\n",
       "0            1            0            0            0            1   \n",
       "1            0            1            0            0            1   \n",
       "2            1            0            0            0            0   \n",
       "3            1            0            0            0            1   \n",
       "4            1            0            0            0            1   \n",
       "\n",
       "   rs9608859_2  rs6006426_0  rs6006426_1  rs6006426_2  predict  \n",
       "0            0            0            1            0      1.0  \n",
       "1            0            0            1            0      0.0  \n",
       "2            1            0            0            1      1.0  \n",
       "3            0            0            1            0      1.0  \n",
       "4            0            0            1            0      0.0  \n",
       "\n",
       "[5 rows x 12334 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cohort = pd.read_csv(os.path.join(data_path, 'for_framingham/processed', 'merged_fr_results.csv'))\n",
    "print(len(df_genetic))\n",
    "df_genetic_merged = df_genetic.merge(df_cohort[['GRID', 'predict']], how='inner', on='GRID')\n",
    "print(len(df_genetic_merged))\n",
    "df_genetic_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_genetic.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_genetic.loc[df_genetic['CLASS'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30248\n"
     ]
    }
   ],
   "source": [
    "df_fram_genetic = df_genetic_merged.loc[((df_genetic_merged['predict']==0) & (df_genetic_merged['CLASS']==1)) | (df_genetic_merged['CLASS']==0)]\n",
    "print(len(df_fram_genetic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6653\n",
      "6653\n"
     ]
    }
   ],
   "source": [
    "print(len(df_fram_genetic.loc[df_fram_genetic['CLASS']==1]))\n",
    "print(len(df_fram_genetic.loc[(df_fram_genetic['CLASS']==1) & (df_fram_genetic['predict']==0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "def encode(X_train, X_test, n_comp): \n",
    "    input_layer = Input(shape=(X_train.shape[1],))\n",
    "    encoded = Dense(n_comp, activation='relu')(input_layer)\n",
    "    decoded = Dense(X_train.shape[1], activation='sigmoid')(encoded) \n",
    "    autoencoder = Model(input_layer, decoded) \n",
    "    \n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    autoencoder.fit(X_train.values, X_train.values, \n",
    "                       epochs=20, \n",
    "                       batch_size=128, \n",
    "                       shuffle=False, validation_data=(X_train.values, X_train.values))\n",
    "    \n",
    "    encoder = Model(input_layer, encoded)\n",
    "    \n",
    "    X_train_encoded = encoder.predict(X_train.values) \n",
    "    X_test_encoded = encoder.predict(X_test.values) \n",
    "    \n",
    "    return X_train_encoded, X_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class EarlyStopAUROC(keras.callbacks.Callback):\n",
    "    def __init__(self, file_path, tolerance=0.001, patience=8, verbose=1):\n",
    "        super(keras.callbacks.Callback, self).__init__()\n",
    "        self.tolerance=tolerance \n",
    "        self.patience=patience\n",
    "        self.verbose=verbose\n",
    "        self.count=0 \n",
    "        self.max=0 \n",
    "        self.file_path = file_path \n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        target = self.validation_data[1]\n",
    "        score = roc_auc_score(target, predict)\n",
    "                   \n",
    "        if score > self.max: \n",
    "            self.max = score\n",
    "            print('\\nSaving weight:\\t{}'.format(self.max))\n",
    "            self.model.save_weights(self.file_path)\n",
    "            self.count = 0 \n",
    "        else: \n",
    "            self.count += 1\n",
    "            \n",
    "        if self.count >= 8: \n",
    "            self.model.stop_trianing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf \n",
    "\n",
    "def auroc(y_true, y_pred):\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    print(auroc)\n",
    "    return auroc \n",
    "\n",
    "# define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505\n",
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value\n",
    "\n",
    "def auc_2(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0\n",
      "(27222, 12331)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected array-like (array or non-string sequence), got <tf.Tensor 'dense_33_target:0' shape=(?, ?) dtype=float32>",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9f6335a52be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_fram_genetic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_fram_genetic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mdict_fold_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_fold_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_genetic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mdf_pred_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_pred_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_fold_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-9f6335a52be9>\u001b[0m in \u001b[0;36mrun_genetic\u001b[0;34m(df_train, df_test)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_network_2_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#     model = get_network_3_bn(input_shape=X_train.shape[1], units=(1024,256,8), dropout=(.2,.2,.1), epsilon=.1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-bcdb983544e6>\u001b[0m in \u001b[0;36mget_network_2_bn\u001b[0;34m(input_shape, units, dropout, epsilon, lr)\u001b[0m\n\u001b[1;32m     42\u001b[0m     model.compile(loss='binary_crossentropy',\n\u001b[1;32m     43\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                   metrics=['accuracy', auroc])\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ML/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, sample_weight_mode, **kwargs)\u001b[0m\n\u001b[1;32m    786\u001b[0m                            \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                            \u001b[0msample_weight_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                            **kwargs)\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ML/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m                     \u001b[0mmetric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                     \u001b[0mmasked_metric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_masked_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                     \u001b[0mmetric_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_metric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m                     metric_result = {\n\u001b[1;32m    971\u001b[0m                         \u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetric_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ML/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mmasked\u001b[0;34m(y_true, y_pred, mask)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \"\"\"\n\u001b[1;32m    484\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-60c3658ee4f2>\u001b[0m in \u001b[0;36mauroc\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mauroc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mauroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauroc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauroc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ML/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    263\u001b[0m     return _average_binary_score(\n\u001b[1;32m    264\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ML/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     68\u001b[0m                          ''.format(average_options))\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ML/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         raise ValueError('Expected array-like (array or non-string sequence), '\n\u001b[0;32m--> 244\u001b[0;31m                          'got %r' % y)\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multilabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got <tf.Tensor 'dense_33_target:0' shape=(?, ?) dtype=float32>"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "\n",
    "\n",
    "def run_genetic(df_train, df_test): \n",
    "    X_train, y_train = df_train.drop(['CLASS', 'GRID', 'predict'], axis=1), df_train['CLASS']\n",
    "    X_test, y_test = df_test.drop(['CLASS', 'GRID', 'predict'], axis=1), df_test['CLASS']\n",
    "\n",
    "#     rand_proj = GaussianRandomProjection(n_components=200)\n",
    "#     rand_proj.fit(X_train)\n",
    "#     X_train = rand_proj.transform(X_train)\n",
    "\n",
    "    if False: \n",
    "        X_train, X_test = encode(X_train, X_test, n_comp=2000)\n",
    "\n",
    "    print(X_train.shape) \n",
    "    \n",
    "    model = get_network_2_bn(input_shape=X_train.shape[1], units=(512,8), dropout=(.2,.1), epsilon=.01)\n",
    "#     model = get_network_3_bn(input_shape=X_train.shape[1], units=(1024,256,8), dropout=(.2,.2,.1), epsilon=.1)\n",
    "    \n",
    "    print('# of subjects in cohort:\\t{}'.format(len(df_fram_genetic)))\n",
    "#     print('# of features in cohort:\\t{}'.format(len(df_fram_genetic.columns)))\n",
    "    \n",
    "    hdf5_file_path = os.path.join(results_path, 'test_genetic.hdf5')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=30, min_lr=0.000001, verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath=hdf5_file_path, monitor='val_auroc', verbose=1, mode='max', \n",
    "                                   save_best_only=True)\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_auc_2',\n",
    "                               min_delta=.001,\n",
    "                               patience=8,\n",
    "                               verbose=1,\n",
    "                               mode='max')\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    num_epochs = 100\n",
    "\n",
    "    class_weight_vec = compute_class_weight(class_weight='balanced',\n",
    "                                            classes=[0,1],\n",
    "                                            y=y_train)\n",
    "    \n",
    "    history_model = model.fit(X_train,\n",
    "                              y_train,\n",
    "                              batch_size=256,\n",
    "                              class_weight={0: class_weight_vec[0], 1: class_weight_vec[1]},\n",
    "                              epochs=num_epochs,\n",
    "                              verbose=1,\n",
    "                              validation_split=0.11, callbacks=[reduce_lr, checkpointer])\n",
    "\n",
    "    model.load_weights(hdf5_file_path)\n",
    "\n",
    "#     X_test = rand_proj.transform(X_test)\n",
    "    y_score = model.predict(X_test)\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_score)  # main_input\n",
    "    # cvs_aucs.append(auc)\n",
    "    ap = average_precision_score(y_test, y_score)\n",
    "\n",
    "\n",
    "    dict_train_history = {'epoch': list(range(len(history_model.history['val_loss']))),\n",
    "                          'val_loss': history_model.history['val_loss'],\n",
    "                          'loss': history_model.history['loss'],\n",
    "                          'val_acc': history_model.history['val_acc'],\n",
    "                          'acc': history_model.history['acc'],\n",
    "                          'fold': [fold] * len(history_model.history['val_loss'])}\n",
    "    \n",
    "    return {'CLASS': list(y_test), 'SCORE': list(y_score)}, dict_train_history\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(X=df_fram_genetic,\n",
    "                 y=df_fram_genetic['CLASS'])\n",
    "#\n",
    "# feat_lst = list(df_fram_genetic.columns)\n",
    "# feat_lst.remove('CLASS')\n",
    "# feat_lst.remove('GRID')\n",
    "#\n",
    "# df_pred_cv = pd.DataFrame()\n",
    "# df_feat_cv = pd.DataFrame({'FEATURE': feat_lst})\n",
    "\n",
    "df_pred_cv = pd.DataFrame()\n",
    "df_train_cv = pd.DataFrame()\n",
    "\n",
    "fold = 0\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X=df_fram_genetic,\n",
    "                                         y=df_fram_genetic['CLASS']):\n",
    "    \n",
    "    print('FOLD: {}'.format(fold))\n",
    "\n",
    "    df_train, df_test = df_fram_genetic.iloc[train_index], df_fram_genetic.iloc[test_index]\n",
    "\n",
    "    dict_fold_pred, dict_fold_train = run_genetic(df_train, df_test) \n",
    "        \n",
    "    df_pred_cv = pd.concat([df_pred_cv, pd.DataFrame(dict_fold_pred)]) \n",
    "#     df_cv = pd.concat([df_cv, pd.DataFrame({'FOLD': [fold], 'AUC': [auc], 'AP': [ap]})])\n",
    "    df_train_cv = pd.concat([df_train_cv, pd.DataFrame(dict_fold_train)])\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "    break\n",
    "\n",
    "# return df_cv, df_cv_train_history\n",
    "# fold = 0\n",
    "# for train_index, test_index in skf.split(X=df_fram_genetic,\n",
    "#                                          y=df_fram_genetic['CLASS']):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.255625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.314649]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.592135]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.52449]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.115576]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLASS       SCORE\n",
       "0      0  [0.255625]\n",
       "1      0  [0.314649]\n",
       "2      0  [0.592135]\n",
       "3      1   [0.52449]\n",
       "4      0  [0.115576]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.547425179417\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f953979f358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_score = list(df_pred_cv['SCORE']) \n",
    "y_test = list(df_pred_cv['CLASS'])\n",
    "y_pred = [0 if score < .5 else 1 for score in y_score]\n",
    "\n",
    "print(roc_auc_score(y_test, y_score))\n",
    "\n",
    "plt.plot(df_train_cv['epoch'], df_train_cv['val_loss'])\n",
    "plt.plot(df_train_cv['epoch'], df_train_cv['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAEmCAYAAAAnRIjxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h8ypE310lqFZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4455144f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "c_matrix_norm = c_matrix.astype('float') / c_matrix.sum()\n",
    "c_matrix_norm\n",
    "\n",
    "plt.imshow(c_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix') \n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(['no CVD', 'CVD']))\n",
    "plt.xticks(tick_marks, ['no CVD', 'CVD'], rotation=45)\n",
    "plt.yticks(tick_marks, ['no_CVD', 'CVD'], rotation=45)\n",
    "                        \n",
    "fmt = 'd'\n",
    "thresh = c_matrix.max() / 4.\n",
    "for i, j in itertools.product(range(c_matrix.shape[0]), range(c_matrix.shape[1])):\n",
    "#     plt.text(j, i, format(c_matrix[i, j], fmt),\n",
    "    plt.text(j, i, '{}\\n{}'.format(c_matrix[i,j], format(c_matrix_norm[i,j], '.2f')),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if c_matrix[i, j] == c_matrix.max() else \"black\")\n",
    "    \n",
    "plt.tight_layout() \n",
    "plt.ylabel('True label') \n",
    "plt.xlabel('Pred label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "model = 'rf' \n",
    "name = '_no_pm_bin_reg_no_std'\n",
    "\n",
    "# df_pred_1 = pd.read_csv(os.path.join(csv_path, folder, '{}_pred_{}{}.csv'.format(model, 'fram', name)))\n",
    "# df_pred_2 = pd.read_csv(os.path.join(csv_path, folder, '{}_pred_{}{}.csv'.format(model, 'full', name)))\n",
    "\n",
    "\n",
    "n_classes = 2\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_score)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# # Compute micro-average ROC curve and ROC area\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(df_pred['PRED'].ravel(), df_pred['SCORE'].ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "lw = 2\n",
    "plt.plot(fpr[1], tpr[1], color='orange',  \n",
    "         lw=lw, label='Fram ROC curve (area = {})'.format(round(roc_auc[1], 3)))\n",
    "\n",
    "\n",
    "# n_classes = 2\n",
    "# # Compute ROC curve and ROC area for each class\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "# for i in range(n_classes):\n",
    "#     fpr[i], tpr[i], _ = roc_curve(df_pred_2['CLASS'], df_pred_2['SCORE'])\n",
    "#     roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "# plt.plot(fpr[1], tpr[1], color='green', linestyle='--', \n",
    "#          lw=lw, label='Full ROC curve (area = {})'.format(round(roc_auc[1], 3)))\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=lw, linestyle='-.')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}