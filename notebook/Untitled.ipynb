{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import statistics \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_full = pd.read_csv('/legodata/zhaoj/cvd_risk_time2/src/ML/csv/bench_7/rf_pred_full.csv')\n",
    "lr_full = pd.read_csv('/legodata/zhaoj/cvd_risk_time2/src/ML/csv/bench_7/lr_pred_full.csv') \n",
    "gbt_full = pd.read_csv('/legodata/zhaoj/cvd_risk_time2/src/ML/csv/bench_7/gbt_pred_full.csv') \n",
    "\n",
    "rf_fram = pd.read_csv('/legodata/zhaoj/cvd_risk_time2/src/ML/csv/bench_7/rf_pred_fram.csv')\n",
    "lr_fram = pd.read_csv('/legodata/zhaoj/cvd_risk_time2/src/ML/csv/bench_7/lr_pred_fram.csv') \n",
    "gbt_fram = pd.read_csv('/legodata/zhaoj/cvd_risk_time2/src/ML/csv/bench_7/gbt_pred_fram.csv') \n",
    "\n",
    "rf_true_fram = pd.read_csv('/legodata/zhaoj/cvd_risk_time2/src/ML/csv/bench_7/rf_pred_true_fram.csv')\n",
    "lr_true_fram = pd.read_csv('/legodata/zhaoj/cvd_risk_time2/src/ML/csv/bench_7/lr_pred_true_fram.csv') \n",
    "gbt_true_fram = pd.read_csv('/legodata/zhaoj/cvd_risk_time2/src/ML/csv/bench_7/gbt_pred_true_fram.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.657401929885\n",
      "0.008911048178783233\n",
      "0.624557566735\n",
      "0.010215848481164894\n",
      "0.657448494761\n",
      "0.012489222617149898\n",
      "0.699045144178\n",
      "0.00844312520073332\n",
      "0.700847941413\n",
      "0.008203648015163482\n",
      "0.722806335447\n",
      "0.008045499161695682\n",
      "0.702555226701\n",
      "0.005528626328012697\n",
      "0.680510302452\n",
      "0.008602926357389427\n",
      "0.702330341018\n",
      "0.012821887265239328\n"
     ]
    }
   ],
   "source": [
    "for df_full, df_fram, df_true_fram in [(gbt_full, gbt_fram, gbt_true_fram), (rf_full, rf_fram, rf_true_fram), (lr_full, lr_fram, lr_true_fram)]:\n",
    "    for df_pred in [df_full, df_fram, df_true_fram]: \n",
    "        auroc_lst = list() \n",
    "        avg = 0 \n",
    "        for i in range(10): \n",
    "            df_pred_fold = df_pred.loc[df_pred['FOLD'] == i]\n",
    "            auc = roc_auc_score(df_pred_fold['CLASS'], df_pred_fold['SCORE'])\n",
    "            auroc_lst.append(auc)\n",
    "\n",
    "            avg += auc\n",
    "        print(avg / 10)\n",
    "        print(statistics.stdev(auroc_lst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.657448494761\n",
      "0.657401929885\n",
      "Ttest_indResult(statistic=0.0095976915047339528, pvalue=0.99244784258606489)\n",
      "0.702330341018\n",
      "0.702555226701\n",
      "Ttest_indResult(statistic=-0.050930953408831539, pvalue=0.95994147558096421)\n",
      "0.722806335447\n",
      "0.699045144178\n",
      "Ttest_indResult(statistic=6.4427687043669639, pvalue=4.6098693510094334e-06)\n"
     ]
    }
   ],
   "source": [
    "for full, fram in [(gbt_full, gbt_true_fram), (lr_full, lr_true_fram), (rf_full, rf_true_fram)]: \n",
    "    auc_dict = {'full': [], 'fram': []} \n",
    "    \n",
    "    fram_avg = 0 \n",
    "    full_avg = 0 \n",
    "    \n",
    "    for i in range(10): \n",
    "        fram_fold = full.loc[full['FOLD'] == i]\n",
    "        full_fold = fram.loc[fram['FOLD'] == i] \n",
    "        full_auc = roc_auc_score(full_fold['CLASS'], full_fold['SCORE'])\n",
    "        fram_auc = roc_auc_score(fram_fold['CLASS'], fram_fold['SCORE']) \n",
    "        \n",
    "        full_avg += full_auc \n",
    "        fram_avg += fram_auc \n",
    "        \n",
    "        auc_dict['full'].append(full_auc)\n",
    "        auc_dict['fram'].append(fram_auc) \n",
    "        \n",
    "    full_avg /= 10 \n",
    "    fram_avg /= 10 \n",
    "    \n",
    "    print(full_avg)\n",
    "    print(fram_avg)\n",
    "    \n",
    "    df_auc = pd.DataFrame(auc_dict)\n",
    "    \n",
    "    print(ttest_ind(auc_dict['full'], auc_dict['fram']))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
